{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Perform standard offline calculations for POD\n",
    "-----------------------------------------------\n",
    "##POD for the solution\n",
    "1. Read in solution snapshots, $\\mathbf{S} \\in R^{N \\times n_{s}}$\n",
    "2. Compute SVD for solution snapshots, $\\mathbf{S} = \\mathbf{U}\\mathbf{\\Sigma} \\mathbf{W}^T$. Save $\\mathbf{U}$, diag($\\Sigma$) to separate files\n",
    "3. Calculate which level of truncation gives you 99.99\\% of the 'energy' from $\\mathbf{S}$\n",
    "4. Define $\\tilde{\\mathbf{U}} = \\mathbf{U}_{i,j}, 1 \\le i \\le N, 1 \\le j \\le m$. Save $\\tilde{\\mathbf{U}}$ to a file.\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#some preliminaries\n",
    "import numpy as np\n",
    "import scipy\n",
    "from proteus.iproteus import *\n",
    "from proteus import deim_utils,Archiver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#read snapshots\n",
    "sim_archive = \"burgers_1d\"\n",
    "archive = Archiver.XdmfArchive(\".\",sim_archive,readOnly=True)\n",
    "\n",
    "#should be able to find this out with a query or something\n",
    "n_s = 100; soln_name='u'\n",
    "S = deim_utils.read_snapshots(archive,n_s+1,soln_name)\n",
    "U, s, W = np.linalg.svd(S, full_matrices=False)\n",
    "\n",
    "print 'SVD for solution done!'\n",
    "np.savetxt('SVD_basis', U, delimiter=' ')\n",
    "np.savetxt('Singular_values', s, delimiter=' ')\n",
    "\n",
    "total_energy = s.sum(); assert total_energy > 0.\n",
    "m,energy=0,0.\n",
    "while energy/total_energy < 0.9999 and m < len(s):\n",
    "    m += 1\n",
    "    energy = s[:m].sum()\n",
    "#\n",
    "print 'truncation level for 99.99% = {0}, \\sigma_{1} = {2}'.format(m,m+1,s[m+1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.savetxt('SVD_basis_truncated_{0}'.format(m), U[:,0:m], delimiter=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot the singular values\n",
    "plt.semilogy(s,'o')\n",
    "plt.xlabel('mode'); plt.ylabel('solution singular values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##POD for the nonlinear snapshots\n",
    "1. Read in solution snapshots, $\\mathbf{S}_f \\in R^{N \\times n_{s}}$\n",
    "2. Compute SVD for solution snapshots, $\\mathbf{S}_f = \\mathbf{U}_f\\mathbf{\\Sigma}_f \\mathbf{W}_f^T$. Save $\\mathbf{U}_f$, diag($\\Sigma_f$) to separate files\n",
    "3. Calculate which level of truncation gives you 99.99\\% of the 'energy' from $\\mathbf{S}$\n",
    "4. Define $\\tilde{\\mathbf{U}}_f = \\mathbf{U}_{f,i,j}, 1 \\le i \\le N, 1 \\le j \\le m_f$. Save $\\tilde{\\mathbf{U}}_f$ to a file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nonlin_name='spatial_residual0'\n",
    "Sf = deim_utils.read_snapshots(archive,n_s+1,nonlin_name)\n",
    "Uf,sf,Vf = np.linalg.svd(Sf,full_matrices=False)\n",
    "\n",
    "print 'SVD for spatial residual done!'\n",
    "np.savetxt('Fs_SVD_basis', Uf, delimiter=' ')\n",
    "np.savetxt('Fs_Singular_values', sf, delimiter=' ')\n",
    "\n",
    "total_energy = sf.sum(); assert total_energy > 0.\n",
    "mf,energy=0,0.\n",
    "while energy/total_energy < 0.9999 and mf < len(sf):\n",
    "    mf += 1\n",
    "    energy = sf[:mf].sum()\n",
    "#\n",
    "print 'truncation level for 99.99% = {0}, \\sigma_{1} = {2}'.format(mf,mf+1,sf[mf+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#override truncation level if desired\n",
    "set_manual_hyper_modes=True\n",
    "if set_manual_hyper_modes:\n",
    "    mf = 73"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Vf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot the singular values\n",
    "plt.semilogy(sf,'r*')\n",
    "plt.xlabel('mode'); plt.ylabel('nonlinearity singular values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##DEIM for evaluation of the nonlinearity\n",
    "1. Set $\\vec{\\rho}, \\tilde{\\mathbf{U}}_f \\leftarrow \\mbox{DEIM}(m_f,\\tilde{\\mathbf{U}}_f)$\n",
    "2. Write out indices $\\rho$ to a file- pick $m$, dimension for $F$ reduced basis $\\mathbf{U}_m$\n",
    "3. Formally build $\\mathbf{P}$ from $\\rho$ as \n",
    "    $$\n",
    "    \\mathbf{P} = [\\vec e_{\\rho_1},\\vec e_{\\rho_2},\\dots,\\vec e_{\\rho_m}]\n",
    "    $$\n",
    "   Really just save $\\vec{\\rho}$ as a vector for evaluations\n",
    "4. Invert $\\mathbf{P}^T\\tilde{\\mathbf{U}}_f$\n",
    "5. Set $\\mathbf{Q}=\\tilde{\\mathbf{U}}_f(\\mathbf{P}^T\\tilde{\\mathbf{U}}_f)^{-1}$\n",
    "6. Save $\\mathbf{Q}$ to a file.\n",
    "\n",
    "During evolution\n",
    "1. Project to fine grid $\\vec v = \\tilde{\\mathbf{U}} \\vec z$\n",
    "2. Evaluate $\\vec F(\\tilde{\\mathbf{U}}\\vec z)$ at indices in $\\vec \\rho \\rightarrow \\vec c$\n",
    "3. Apply DEIM interpolant $\\tilde{\\vec F} = \\tilde{\\mathbf{U}}^T\\mathbf{Q}\\vec c$\n",
    "4. Use $\\tilde{\\vec F}$ in evaluation of reduced system\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rho,Q = deim_utils.deim_alg(Uf,mf)\n",
    "plt.plot(rho,'o')\n",
    "plt.xlabel('mode'); plt.ylabel('DEIM index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('Fs_SVD_basis_truncated_{0}'.format(mf), Uf[:,0:mf], delimiter=' ')\n",
    "np.savetxt('Q_DEIM_truncated_{0}'.format(mf),Q,delimiter=' ')\n",
    "np.savetxt('DEIM_indices_{0}'.format(mf),rho,delimiter=' ',fmt='%d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Q_reload = np.loadtxt('Q_DEIM_truncated_73')\n",
    "np.max(Q_reload-Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Now actually try gappy POD for evaluating nonlinearity\n",
    "\n",
    "The process as I understand it for gappy pod is\n",
    "\n",
    "1. Compute $M$ snapshots for high dimensional nonlinear function \n",
    "$$\n",
    "\\mathbf{S} = [\\vec f^1, \\vec f^2, \\dots, \\vec f^M] \\in \\Re^{n \\times M} \n",
    "$$\n",
    "2. Compute standard POD basis for snapshots\n",
    "$$\n",
    "\\mathbf{S} = \\mathbf{U}_F\\mathbf{\\Sigma}_F\\mathbf{W}_F^T\n",
    "$$\n",
    "3. Pick a truncation level for basis, $m$\n",
    "3. Pick $k$ indices for sampling from nonlinear function. DEIM will give us $k=m$ indices. Do I want more according to Ansallem slides? Is the Wilcox procedure different/better?\n",
    "$$\n",
    "\\mathcal{I} = \\{i_1,i_2,\\dots,i_k\\}\n",
    "$$\n",
    "To tie back to the DEIM formalism, we'll refer to the $k$ dimensional vector holding the entries\n",
    "of $\\mathcal{I}$ as $\\vec \\rho$.\n",
    "4. Solve least-squares problem to minimize error in interpolation assuming that we are using the specified sampling indices. \n",
    "    - Define sample matrix $\\mathbf{P} = [\\vec e_{i_1}, \\vec e_{i_2}, \\dots, \\vec e_{i_k}]$\n",
    "    - I believe we technically solve the following problem at each time step\n",
    "    $$\n",
    "    \\vec c = \\mbox{arg min}_{\\vec y}\\|\\mathbf{P}^T\\mathbf{U}_m\\vec y - \\mathbf{P}^T\\vec f\\|_2\n",
    "    $$\n",
    " \n",
    "The solution to this least squares minimization problem is \n",
    "\n",
    "- Define $\\mathbf{M} = \\mathbf{P^T}\\mathbf{U}_m \\in \\Re^{k \\times m}$\n",
    "- Perform SVD of $\\mathbf{M} = \\hat{\\mathbf{U}}\\hat{\\mathbf{\\Sigma}}\\hat{\\mathbf{W}}^T$. Here \n",
    "  $\\hat{\\mathbf{U}} \\in \\Re^{k \\times k}$, $\\hat{\\mathbf{W}} \\in \\Re^{m \\times m}$, and   $\\hat{\\mathbf{\\Sigma}} \\in \\Re^{k \\times m}$. \n",
    "   \n",
    "- Define the Moore-Penrose pseudoinverse\n",
    "\n",
    "    $$\n",
    "    \\mathbf{M}^{\\dagger} = \\hat{\\mathbf{W}}\\hat{\\mathbf{\\Sigma}}^{\\dagger}\\hat{\\mathbf{U}}^{T}\n",
    "    $$ \n",
    "    where $\\hat{\\mathbf{\\Sigma}}^{\\dagger} \\in \\Re^{m\\times k}$ with the nonzero entries  given by\n",
    "    \n",
    "    $$\n",
    "    \\hat{\\Sigma}^{\\dagger}_{ii}= 1/\\Sigma_{ii}, \\mbox{ if } \\Sigma_{ii} > 0\n",
    "    $$\n",
    "- set $\\vec c = \\mathbf{M}^{\\dagger}\\mathbf{P}^T\\vec f$    \n",
    "\n",
    "I believe we can compute the Moore-Penrose pseudoinverse with `numpy.linalg.pinv`  \n",
    "\n",
    "Alternatively, we could just use numpy's least squares algorithm or the QR factorization suggested by Carlberg et al in their 2011 paper. _Note_ this $\\mathbf{Q}$ is not the same as the $\\mathbf{Q}$ in the final hyper-reduction approximation.\n",
    "\n",
    "$$\n",
    "\\mathbf{Q}\\mathbf{R} = \\mathbf{M}, \\ \\ \\mathbf{Q} \\in \\Re^{k,\\ell}, \\ \\ell = \\min(k,m), \\mathbf{R} \\in \\Re^{\\ell,m}\n",
    "$$\n",
    "solve (note we require $k \\ge m$ )\n",
    "$$\n",
    "\\mathbf{R}\\vec c = \\mathbf{Q}^T\\mathbf{P}^T\\vec f\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gappy_indices_11(Uin,nind_target,verbose=0):\n",
    "    \"\"\"\n",
    "    Try to implement greedy algorithm from Carlberg et al 2011\n",
    "    \n",
    "    input: Uin n x m array of basis vectors for nonlinear function snapshots\n",
    "    nind_target: number of indices would like to use\n",
    "    output: rho, m vector of indices \\rho_i for extracting $\\vec F$ values\n",
    "\n",
    "    \"\"\"\n",
    "    n,ns = Uin.shape\n",
    "    indices = set()#mathcal{I}\n",
    "    nind = 0\n",
    "    m=0\n",
    "    r=Uin[:,0]\n",
    "    niter = 0\n",
    "    while nind < nind_target and niter < n:\n",
    "        rind = np.argmax(np.absolute(r)) \n",
    "        if not rind in indices:\n",
    "            indices.add(rind)\n",
    "        if verbose > 0:\n",
    "            print 'Gappy alg. nind={0} chose rind={1}'.format(nind,rind)\n",
    "        #mathcal{K} in algorithm\n",
    "        neigs = set([max(0,rind-1)]+[min(n-1,rind+1)])\n",
    "        indices |= neigs\n",
    "        nind = len(indices)\n",
    "        m += 1\n",
    "        mmin = min(m,ns-1)\n",
    "        p = min(m-1,ns-1)\n",
    "        rho = np.array(list(indices),dtype='i')\n",
    "        U = Uin[:,0:p+1]\n",
    "        u = Uin[:,mmin]\n",
    "        c,l2res,rank,svals = np.linalg.lstsq(U[rho],u[rho])\n",
    "        r = u-np.dot(U,c)\n",
    "        #kill indices that have already been selected\n",
    "        r[rho] = 0.0\n",
    "        niter += 1\n",
    "    #\n",
    "    return rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = Uf.shape[0] \n",
    "percent = 1.#0.3\n",
    "ntarget = min(max(int(n*percent),mf),n)\n",
    "rho_gappy = gappy_indices_11(Uf,ntarget,verbose=1)\n",
    "#add inflow as well\n",
    "inflow_boundary_indices = [0]\n",
    "for I in inflow_boundary_indices:\n",
    "    if I not in rho_gappy:\n",
    "        tmp = np.zeros(rho_gappy.shape[0]+1,'i')\n",
    "        tmp[0:-1] = rho_gappy\n",
    "        tmp[-1]=0\n",
    "        rho_gappy = tmp[:]\n",
    "n_sample = rho_gappy.shape[0]\n",
    "print 'after calling Carlberg etal 11 greedy algorithm target indices={0}, actual = {1} rho= {2} '.format(ntarget,len(rho_gappy),rho_gappy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rho_gappy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(rho_gappy,'o')\n",
    "plt.xlabel('mode'); plt.ylabel('Gappy  index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Calculate $\\mathbf{P}^T\\mathbf{U}_m$ by just extracting rows in numpy \n",
    "\n",
    "###Then invert and set $\\mathbf{P}_F=\\mathbf{U}_m (\\mathbf{P}^T\\mathbf{U}_m)^{\\dagger})$\n",
    "\n",
    "###Note, I need to finish making the notation consistent between DEIM above and Gappy POD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Um = Uf[:,0:mf]\n",
    "PtUm_gappy = Um[rho_gappy]\n",
    "assert PtUm_gappy.shape == (n_sample,mf)\n",
    "\n",
    "PtUmInv_gappy = np.linalg.pinv(PtUm_gappy)\n",
    "Q_gappy= np.dot(Um,PtUmInv_gappy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.savetxt('Fs_SVD_basis_truncated_{0}'.format(mf), Um, delimiter=' ')\n",
    "np.savetxt('Fs_Gappy_indices_truncated_{0}'.format(n_sample),rho_gappy,delimiter=' ',fmt='%d')\n",
    "np.savetxt('Q_Gappy_truncated_{0}_{1}'.format(mf,n_sample),Q_gappy,delimiter=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes from GNAT\n",
    "---------------\n",
    "- good rule of thumb is 99.99% of basis\n",
    "- read refs [35] (Everson et al Journal of the optical society of america), [20] 346-366 (Ryckellynck D JCP 202 2005, [34], galbaly, ghattas, ijnme 2010\n",
    "- implement GNAT burgers equation\n",
    "- GNAT only uses snapshot strategy 0 or 1\n",
    "- think about hyperreduction implementation as sample mesh\n",
    "- read up on linear least squares, Moore-Penrose pseudo inverse\n",
    "- recommends always having at least one sample index on inflow and outflow and at least one area that has sensitivity to input parameters that are driving snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
